{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jan 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n",
      "0  0.00632  18.0   2.31     0  0.538  ...  296.0     15.3  396.90   4.98  24.0\n",
      "1  0.02731   0.0   7.07     0  0.469  ...  242.0     17.8  396.90   9.14  21.6\n",
      "2  0.02729   0.0   7.07     0  0.469  ...  242.0     17.8  392.83   4.03  34.7\n",
      "3  0.03237   0.0   2.18     0  0.458  ...  222.0     18.7  394.63   2.94  33.4\n",
      "4  0.06905   0.0   2.18     0  0.458  ...  222.0     18.7  396.90   5.33  36.2\n",
      "\n",
      "[5 rows x 14 columns]\n",
      "Coefficients: [-1.19443447e-01  4.47799511e-02  5.48526168e-03  2.34080361e+00\n",
      " -1.61236043e+01  3.70870901e+00 -3.12108178e-03 -1.38639737e+00\n",
      "  2.44178327e-01 -1.09896366e-02 -1.04592119e+00  8.11010693e-03\n",
      " -4.92792725e-01]\n",
      "Intercept: 38.091694926303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBJIT\\AppData\\Local\\Temp\\ipykernel_11560\\2502767351.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv('data/housing.csv', header=None, delim_whitespace=True, names=column_names)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data/housing.csv', header=None, delim_whitespace=True, names=column_names)\n",
    "\n",
    "# Check if the data is loaded correctly\n",
    "print(data.head())\n",
    "\n",
    "# Define the dependent variable (y) and independent variables (X)\n",
    "y = data['MEDV']\n",
    "X = data.drop(columns=['MEDV'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the linear regression model\n",
    "linear_fit = LinearRegression()\n",
    "linear_fit.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients:\", linear_fit.coef_)\n",
    "print(\"Intercept:\", linear_fit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Regression of house price on different predictors               \n",
      "==============================================================================\n",
      "Dep. Variable:            House price   R-squared:                       0.773\n",
      "Model:                            OLS   Adj. R-squared:                  0.765\n",
      "Method:                 Least Squares   F-statistic:                     102.2\n",
      "Date:                Sat, 08 Feb 2025   Prob (F-statistic):          9.64e-117\n",
      "Time:                        13:20:22   Log-Likelihood:                -1171.5\n",
      "No. Observations:                 404   AIC:                             2371.\n",
      "Df Residuals:                     390   BIC:                             2427.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         38.0917      5.522      6.898      0.000      27.234      48.949\n",
      "CRIM          -0.1194      0.037     -3.257      0.001      -0.192      -0.047\n",
      "ZN             0.0448      0.014      3.102      0.002       0.016       0.073\n",
      "INDUS          0.0055      0.063      0.087      0.931      -0.119       0.130\n",
      "CHAS           2.3408      0.902      2.595      0.010       0.567       4.115\n",
      "NOX          -16.1236      4.212     -3.828      0.000     -24.404      -7.843\n",
      "RM             3.7087      0.458      8.106      0.000       2.809       4.608\n",
      "AGE           -0.0031      0.014     -0.218      0.828      -0.031       0.025\n",
      "DIS           -1.3864      0.214     -6.480      0.000      -1.807      -0.966\n",
      "RAD            0.2442      0.070      3.481      0.001       0.106       0.382\n",
      "TAX           -0.0110      0.004     -2.819      0.005      -0.019      -0.003\n",
      "PTRATIO       -1.0459      0.137     -7.636      0.000      -1.315      -0.777\n",
      "B              0.0081      0.003      2.749      0.006       0.002       0.014\n",
      "LSTAT         -0.4928      0.054     -9.086      0.000      -0.599      -0.386\n",
      "==============================================================================\n",
      "Omnibus:                      141.494   Durbin-Watson:                   1.996\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              629.882\n",
      "Skew:                           1.470   Prob(JB):                    1.67e-137\n",
      "Kurtosis:                       8.365   Cond. No.                     1.55e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.55e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary(title=\"Regression of house price on different predictors\", yname=\"House price\"))\n",
    "\n",
    "# Save the summary to a text file\n",
    "with open(\"reports/Regression.txt\", \"w\") as f:\n",
    "    f.write(model.summary(title=\"Regression of house price on different predictors\", yname=\"House price\").as_text())\n",
    "    \n",
    "with open(\"reports/Regression.html\", \"w\") as f:\n",
    "    f.write(model.summary(title=\"Regression of house price on different predictors\", yname=\"House price\").as_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, norm\n",
    "\n",
    "# Problem 1: Population Regression vs Least Squares Regression\n",
    "np.random.seed(123)\n",
    "n = 50\n",
    "x = uniform.rvs(5, 5, size=n)\n",
    "error = norm.rvs(0, 42, size=n)\n",
    "y = 2 + 3*x + error\n",
    "\n",
    "# Population regression line\n",
    "y_pop = 2 + 3*x\n",
    "\n",
    "# Least Squares Regression\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Plot\n",
    "plt.scatter(x, y, label=\"Generated Data\")\n",
    "plt.plot(np.sort(x), np.sort(y_pop), color='blue', label=\"Population Regression\")\n",
    "plt.plot(np.sort(x), np.sort(model.predict(X)), color='red', label=\"Least Squares Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Problem 2: RSS Minimization\n",
    "x = uniform.rvs(5, 5, size=n)\n",
    "x_centered = x - np.mean(x)\n",
    "error = norm.rvs(0, 1, size=n)\n",
    "y = 2 + 3*x + error\n",
    "\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "b0_hat, b1_hat = model.params\n",
    "beta0_seq = np.linspace(b0_hat - 2, b0_hat + 2, 100)\n",
    "beta1_seq = np.linspace(b1_hat - 2, b1_hat + 2, 100)\n",
    "rss_vals = np.zeros((100, 100))\n",
    "\n",
    "for i, b0 in enumerate(beta0_seq):\n",
    "    for j, b1 in enumerate(beta1_seq):\n",
    "        y_pred = b0 + b1 * x\n",
    "        rss_vals[i, j] = np.sum((y - y_pred) ** 2)\n",
    "\n",
    "min_rss_idx = np.unravel_index(np.argmin(rss_vals), rss_vals.shape)\n",
    "print(\"Optimal (b0, b1) at minimum RSS:\", beta0_seq[min_rss_idx[0]], beta1_seq[min_rss_idx[1]])\n",
    "\n",
    "# Problem 3: Unbiased Least Squares Estimators\n",
    "beta0_estimates = []\n",
    "beta1_estimates = []\n",
    "for _ in range(100):\n",
    "    x = uniform.rvs(0, 1, size=n)\n",
    "    error = norm.rvs(0, 1, size=n)\n",
    "    y = 2 + 3*x + error\n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    beta0_estimates.append(model.params[0])\n",
    "    beta1_estimates.append(model.params[1])\n",
    "\n",
    "print(\"Average b0:\", np.mean(beta0_estimates))\n",
    "print(\"Average b1:\", np.mean(beta1_estimates))\n",
    "\n",
    "# Problem 7: Ignoring Interaction Terms\n",
    "n = 100\n",
    "x1 = norm.rvs(0, 1, size=n)\n",
    "x2 = np.random.binomial(1, 0.3, size=n)\n",
    "error = norm.rvs(0, 1, size=n)\n",
    "y = -2.5 + 1.2*x1 + 2.3*x2 + 0.001*x1*x2 + error\n",
    "\n",
    "X_interaction = sm.add_constant(np.column_stack((x1, x2, x1*x2)))\n",
    "X_naive = sm.add_constant(np.column_stack((x1, x2)))\n",
    "model_interaction = sm.OLS(y, X_interaction).fit()\n",
    "model_naive = sm.OLS(y, X_naive).fit()\n",
    "\n",
    "mse_interaction = np.mean(model_interaction.resid ** 2)\n",
    "mse_naive = np.mean(model_naive.resid ** 2)\n",
    "print(\"MSE with Interaction:\", mse_interaction, \"MSE without Interaction:\", mse_naive)\n",
    "\n",
    "# Problem 11: KNN vs Least Squares Regression\n",
    "n = 1000\n",
    "x1 = norm.rvs(0, 22, size=n)\n",
    "x2 = np.random.poisson(1.5, size=n)\n",
    "y = -2 + 1.4*x1 - 2.6*x2 + norm.rvs(0, 1, size=n)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.column_stack((x1, x2)), y, train_size=0.8, random_state=123)\n",
    "\n",
    "# Least Squares Regression\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "lm_model = sm.OLS(y_train, X_train_sm).fit()\n",
    "test_mse_lm = np.mean((lm_model.predict(X_test_sm) - y_test) ** 2)\n",
    "\n",
    "# KNN Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "k_values = [1, 2, 5, 9, 15]\n",
    "knn_mse = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    knn_mse.append(np.mean((y_pred - y_test) ** 2))\n",
    "\n",
    "print(\"Test MSE LM:\", test_mse_lm, \"KNN MSEs:\", knn_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
